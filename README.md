# :cloud_with_lightning: AWS-Cloud-Internship-2022 :cloud_with_rain:
![image](https://github.com/ali-arifin/AWS-Cloud-Internship-2022-/assets/103297661/a3ab42e5-438f-4782-b084-e9069c3ab0cd)

|   <ins>Task#</ins>    | <ins>Description</ins> |
| ------------- | ------------- |
|   Task1    | Launched EC2 instances, domain-joined EC2 to Active Directory & created users  |
|   Task2    | Created Application Load Balancer for multiple web servers in default VPC  |
|   Task3    | Created my own VPC and Network Load Balancer for multiple web servers  |
|   Task4    | Created S3 bucket, uploaded files via FileZilla, created two IAM users - one having read-only & the other having read-and-write permission  |
|   Task5    | Scheduled EC2 instances using Instance Scheduler |
|   Task6    | Patched Windows & Linux AMIs via Systems Manager's Automation document  |
|   Task7    | Installed softwares on one Windows EC2, created AMI from it and used it to launch multiple EC2s  |
|   Task8    | Created an Amazon WorkSpace  |
|   Task9    | Disabled USB & copy-paste redirection from an EC2 (domain joined to Simple AD)  |
|   Task10   | Took backup & restored an EBS volume by using AWS Backup  |
|   Task11   | Created S3 bucket & uploaded files using AWS CLI  |
|   Task12   | Created RDS DB-instance, connected to it via MySQL Workbench client, created a table using MySQL commands, ran queries  |
|   Task13   | Created a CloudWatch billing alarm and received alerts via SNS. Created a CloudWatch alarm to stop EC2 (metric: CPU utilization) and received alerts via SNS  |
|   Task14   | Created a Lambda function to launch EC2  |
|   Task15   | Scheduled a Lambda function (that creates an EC2) using EventBridge Rule. Scheduled a Lambda function (that creates an EC2) and got the notification via SNS using Step Functions  |
|   Task16   | Migrated local content to the CodeCommit repository  |
|   Task17   | Deployed a sample web app (hosted in S3) to Windows Server EC2 using CodeDeploy  |
|   Task18   | Deployed a sample web app (hosted in GitHub) to Elastic Beanstalk by creating a Continous Delivery pipeline in CodePipeline  |
|   Task19   | Created a cost-optimized EMR cluster (on Spot Instances) and SSH into it  |
|   Task20   | Created a Redshift cluster, loaded data from S3 to Redshift, ran queries & visualized results on charts in the query editor v2  |
|   Task21   | Loaded a dataset in S3, used AWS Glue to crawl & catalog the data, used GlueStudio to perform ETL on data, ran queries on resultant data in Athena  |
|   Task22   | Exported a DynamoDB table to S3. Scheduled the export of a DynamoDB table to S3 using AWS Data Pipeline  |
|   Task23   | Created RDS DB-instance for PostgreSQL, connected to it via pgAdmin, created a table, migrated this database to DynamoDB using DMS  |
|   Task24   | Connected to a private EC2 (in private subnet) via bastion host. Installed GUI on a Linux EC2  |
|   Task25   | Set up NVIDIA Gaming PC & connected to it via NICE DCV client  |
|   Task26   | Obtained a pre-signed URL for S3 object using AWS CLI. Verified checksum value of an uploaded S3 object to ensure data integrity  |
|   Task27   | Scheduled the deletion of S3 objects at a particular time using AWS Data Pipeline  |
|   Task28  | Visualized data in Amazon RDS MS SQL Express server using Amazon QuickSight  |
